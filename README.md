# Image Captioning

This repository, created as part of the Udacity Nanodegree program, focuses on image captioning. It includes Jupyter Notebooks that provide an overview and implementation details of the image captioning process.

## Overview
- **0_Dataset.html/0_Dataset.ipynb**: Initial exploration and handling of the dataset.
- **1_Preliminaries.html/1_Preliminaries.ipynb**: Preliminary steps and setup for the image captioning model.
- **2_Training.html/2_Training.ipynb**: Training process for the image captioning model.
- **3_Inference.html/3_Inference.ipynb**: Inference and caption generation using the trained model.
- **data_loader.py**: Python script for loading and preprocessing the image captioning dataset.
- **model.py**: Implementation of the image captioning model.
- **vocab.pkl**: Pickle file containing the vocabulary used in the image captioning model.
- **vocabulary.py**: Script for building and handling the vocabulary.

## How to Use
This project, initiated three years ago as part of the Udacity Nanodegree program, demonstrates the process of image captioning. To explore the code and run the experiments, open the Jupyter Notebooks (e.g., 0_Dataset.ipynb, 1_Preliminaries.ipynb, etc.) and execute the cells sequentially.

Please note that this repository was last updated three years ago as part of the Udacity Nanodegree program. The provided materials serve as an introduction to image captioning and offer insights into the implementation of the model.
